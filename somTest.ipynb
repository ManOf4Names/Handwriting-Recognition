{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch of imports\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from som import Kohonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condense_color(tensor):\n",
    "    vect = np.array([])\n",
    "    for i in tensor:\n",
    "        for j in i:\n",
    "            avg = np.average(j.numpy(), returned=True)[0]\n",
    "            if avg > 0.5:\n",
    "                vect = np.append(vect, int(0))\n",
    "            else:\n",
    "                vect = np.append(vect, int(1))\n",
    "    return vect\n",
    "\n",
    "def condense_gray(tensor):\n",
    "    threshold = 0.5\n",
    "    l = tensor.numpy().shape[0]\n",
    "    w = tensor.numpy().shape[1]\n",
    "    vect = tensor.numpy().reshape(-1,) < threshold\n",
    "    # imgPrint(vect, l, w)\n",
    "    return vect\n",
    "\n",
    "def imgPrint(a, l, w):\n",
    "    for i in range(l):\n",
    "        line = \"\"\n",
    "        for j in range(w):\n",
    "            line += str(int(a[i * l + j])) + \" \"\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 731402 files belonging to 62 classes.\n",
      "Using 585122 files for training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nval_ds = tf.keras.utils.image_dataset_from_directory(\\n    input_dir,\\n    labels=\\'inferred\\',\\n    validation_split=val_split,\\n    subset=\"validation\",\\n    seed=123,\\n    image_size=(img_height, img_width),\\n    batch_size=batch_size)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = \"./CharacterSets/Training\"  # Training set directory\n",
    "val_split = 0.2                         # Validation split\n",
    "img_height = img_width = 50             # Height and width of the input images\n",
    "batch_size = 100                        # Batch size\n",
    "\n",
    "# Defining the training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    input_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=val_split,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size)  # WTF does batch size affect????\n",
    "\n",
    "# Defining the validation dataset\n",
    "\"\"\"\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    input_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=val_split,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "train_ds upon initialization is a BatchDataset object\n",
    "mnist in NN.py is a Module object\n",
    "x_train is a complex numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "# print(class_names)\n",
    "\n",
    "# Normalization layer. first_image can be viewed as a numpy array, but currently consists of all 1s for some reason.\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "arr = condense_gray(first_image)\n",
    "\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "# print(np.min(first_image), np.max(first_image))\n",
    "print(type(first_image))\n",
    "testSet = np.array([])\n",
    "for i in range(len(image_batch)):\n",
    "    testSet = np.append(testSet, condense_gray(image_batch[i]))\n",
    "testSet = testSet.reshape(-1, 2500)\n",
    "imgPrint(testSet[0], 50, 50)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3d45ff1cb055de7f48204b82c6f0cd15a6d052971e23d4e794df9cb46eb817a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
