{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch of imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from som import Kohonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condense_color(tensor):\n",
    "    vect = np.array([])\n",
    "    for i in tensor:\n",
    "        for j in i:\n",
    "            avg = np.average(j.numpy(), returned=True)[0]\n",
    "            if avg > 0.5:\n",
    "                vect = np.append(vect, int(0))\n",
    "            else:\n",
    "                vect = np.append(vect, int(1))\n",
    "    return vect\n",
    "\n",
    "def condense_gray(tensor):\n",
    "    threshold = 0.5\n",
    "    l = tensor.numpy().shape[0]\n",
    "    w = tensor.numpy().shape[1]\n",
    "    vect = tensor.numpy().reshape(-1,) < threshold\n",
    "    # imgPrint(vect, l, w)\n",
    "    return vect\n",
    "\n",
    "def imgPrint(a, l, w):\n",
    "    for i in range(l):\n",
    "        line = \"\"\n",
    "        for j in range(w):\n",
    "            line += str(int(a[i * l + j])) + \" \"\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 731402 files belonging to 62 classes.\n",
      "Using 585122 files for training.\n",
      "Found 731402 files belonging to 62 classes.\n",
      "Using 146280 files for validation.\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"./CharacterSets/Training\"  # Training set directory\n",
    "val_split = 0.2                         # Validation split\n",
    "img_height = img_width = 50             # Height and width of the input images\n",
    "batch_size = 100                        # Batch size\n",
    "\n",
    "# Defining the training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    input_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=val_split,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size)  # WTF does batch size affect????\n",
    "\n",
    "# Defining the validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    input_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=val_split,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "for i in y:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "train_ds upon initialization is a BatchDataset object\n",
    "mnist in NN.py is a Module object\n",
    "x_train is a complex numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization layer. first_image can be viewed as a numpy array, but currently consists of all 1s for some reason.\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_train = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "normalized_valid = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch_t, labels_batch_t = next(iter(normalized_train))\n",
    "image_batch_v, labels_batch_v = next(iter(normalized_valid))\n",
    "\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "# print(np.min(first_image), np.max(first_image))\n",
    "trainSet = np.array([])\n",
    "validSet = np.array([])\n",
    "for i in range(len(image_batch_t)):\n",
    "    trainSet = np.append(trainSet, condense_gray(image_batch_t[i]))\n",
    "    validSet = np.append(trainSet, condense_gray(image_batch_v[i]))\n",
    "trainSet = trainSet.reshape(-1, 2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(labels_batch_t[i])\n",
    "    imgPrint(trainSet[i], 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = Kohonen(2500, 100, net_dim=(50, 50), n_classes=62)\n",
    "som.train(trainSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsValid = []\n",
    "labelsTrain = []\n",
    "for i in labels_batch_v:\n",
    "    labelsValid.append(i.numpy())\n",
    "for i in labels_batch_t:\n",
    "    labelsTrain.append(i.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45464/4133662621.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#som.visualize_map(validSet, labelsValid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#som.label_neurons(image_batch_t, labelsTrain)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsValid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Handwriting-Recognition\\som.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, x_test, y_test)\u001b[0m\n\u001b[0;32m     94\u001b[0m             pos = np.unravel_index(\n\u001b[0;32m     95\u001b[0m                 np.argmin(distance, axis=None), distance.shape)\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"0:{pos[0]}\\t1:{pos[1]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#som.visualize_map(validSet, labelsValid)\n",
    "#som.label_neurons(image_batch_t, labelsTrain)\n",
    "print('accuracy', som.accuracy(validSet, labelsValid))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3d45ff1cb055de7f48204b82c6f0cd15a6d052971e23d4e794df9cb46eb817a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
