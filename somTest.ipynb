{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch of imports\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from som import SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"./CharacterSets/Training\"  # Training set directory\n",
    "val_split = 0.2                         # Validation split\n",
    "img_height = img_width = 50             # Height and width of the input images\n",
    "batch_size = 100                        # Batch size\n",
    "\n",
    "# Defining the training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    input_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=val_split,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)  # WTF does batch size affect????\n",
    "\n",
    "# Defining the validation dataset\n",
    "\"\"\"\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    input_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=val_split,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "train_ds upon initialization is a BatchDataset object\n",
    "mnist in NN.py is a Module object\n",
    "x_train is a complex numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "# print(class_names)\n",
    "\n",
    "# Normalization layer. first_image can be viewed as a numpy array, but currently consists of all 1s for some reason.\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "\n",
    "\"\"\"\n",
    "labels = np.array(image_batch, dtype=np.float32)\n",
    "labels = np.reshape(labels, (-1, 1))\n",
    "\n",
    "first_image = np.reshape(first_image, (-1,))\n",
    "\"\"\"\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "som = SOM(50, 50, 1, 0.5, 0.5, 100)\n",
    "som.train(train_ds.take(10).as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to learn more about what train_ds actually is.\n",
    "data = train_ds.take(100)\n",
    "list(data.as_numpy_iterator())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3d45ff1cb055de7f48204b82c6f0cd15a6d052971e23d4e794df9cb46eb817a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
